{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sudhirjoon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sudhirjoon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://capstone-yt-mlflow-bucket/542391321365143307', creation_time=1735485482149, experiment_id='542391321365143307', last_update_time=1735485482149, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://13.60.79.0:5000\")\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:36:02,960] A new study created in memory with name: no-name-5c4ecf0d-9d16-4ac2-b8d0-c9981756e0e3\n",
      "/var/folders/yj/2fr85zvn2sbbpv3jsq4y3kwh0000gn/T/ipykernel_36350/2952957334.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-4, 10.0)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 18:36:03,869] Trial 0 finished with value: 0.7758079912723306 and parameters: {'penalty': None, 'C': 0.005480838304888443}. Best is trial 0 with value: 0.7758079912723306.\n",
      "/var/folders/yj/2fr85zvn2sbbpv3jsq4y3kwh0000gn/T/ipykernel_36350/2952957334.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-4, 10.0)\n",
      "[I 2024-12-29 18:36:04,277] Trial 1 finished with value: 0.7288967680349107 and parameters: {'penalty': 'l1', 'C': 0.05665568045749267}. Best is trial 0 with value: 0.7758079912723306.\n",
      "/var/folders/yj/2fr85zvn2sbbpv3jsq4y3kwh0000gn/T/ipykernel_36350/2952957334.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform(\"C\", 1e-4, 10.0)\n",
      "[W 2024-12-29 18:36:30,869] Trial 2 failed with parameters: {'penalty': 'elasticnet', 'C': 3.7265206692884294, 'l1_ratio': 0.7358566814935423} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yj/2fr85zvn2sbbpv3jsq4y3kwh0000gn/T/ipykernel_36350/2952957334.py\", line 68, in objective_logistic_regression\n",
      "    model.fit(X_train_vec, y_train)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1296, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 540, in _logistic_regression_path\n",
      "    w0, n_iter_i, warm_start_sag = sag_solver(\n",
      "                                   ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py\", line 325, in sag_solver\n",
      "    num_seen, n_iter_ = sag(\n",
      "                        ^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-29 18:36:30,876] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sudhirjoon/Library/Mobile Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone project/experiment-5-LR-with-hpt.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     log_mlflow(\u001b[39m\"\u001b[39m\u001b[39mLogisticRegression\u001b[39m\u001b[39m\"\u001b[39m, best_model, X_train_vec, X_test_vec, y_train, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# Run the Optuna experiment for Logistic Regression\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m run_optuna_experiment()\n",
      "\u001b[1;32m/Users/sudhirjoon/Library/Mobile Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone project/experiment-5-LR-with-hpt.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_optuna_experiment\u001b[39m():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m# Create an Optuna study\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     study\u001b[39m.\u001b[39moptimize(objective_logistic_regression, n_trials\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39m# Get the best hyperparameters and retrain the best model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(catch) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(catch, Iterable) \u001b[39melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/sudhirjoon/Library/Mobile Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone project/experiment-5-LR-with-hpt.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     penalty\u001b[39m=\u001b[39mpenalty,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     C\u001b[39m=\u001b[39mC,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Train and evaluate the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_vec, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_vec)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudhirjoon/Library/Mobile%20Documents/com~apple~CloudDocs/Uni_Mannheim/Sem2/ML_atu/Capstone%20project/experiment-5-LR-with-hpt.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1296\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose, prefer\u001b[39m=\u001b[39mprefer)(\n\u001b[1;32m   1297\u001b[0m     path_func(\n\u001b[1;32m   1298\u001b[0m         X,\n\u001b[1;32m   1299\u001b[0m         y,\n\u001b[1;32m   1300\u001b[0m         pos_class\u001b[39m=\u001b[39mclass_,\n\u001b[1;32m   1301\u001b[0m         Cs\u001b[39m=\u001b[39m[C_],\n\u001b[1;32m   1302\u001b[0m         l1_ratio\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_ratio,\n\u001b[1;32m   1303\u001b[0m         fit_intercept\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept,\n\u001b[1;32m   1304\u001b[0m         tol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol,\n\u001b[1;32m   1305\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   1306\u001b[0m         solver\u001b[39m=\u001b[39msolver,\n\u001b[1;32m   1307\u001b[0m         multi_class\u001b[39m=\u001b[39mmulti_class,\n\u001b[1;32m   1308\u001b[0m         max_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter,\n\u001b[1;32m   1309\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[1;32m   1310\u001b[0m         check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1311\u001b[0m         random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[1;32m   1312\u001b[0m         coef\u001b[39m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1313\u001b[0m         penalty\u001b[39m=\u001b[39mpenalty,\n\u001b[1;32m   1314\u001b[0m         max_squared_sum\u001b[39m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1315\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1316\u001b[0m         n_threads\u001b[39m=\u001b[39mn_threads,\n\u001b[1;32m   1317\u001b[0m     )\n\u001b[1;32m   1318\u001b[0m     \u001b[39mfor\u001b[39;00m class_, warm_start_coef_ \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1319\u001b[0m )\n\u001b[1;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:540\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    537\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[1;32m    538\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[0;32m--> 540\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[1;32m    541\u001b[0m         X,\n\u001b[1;32m    542\u001b[0m         target,\n\u001b[1;32m    543\u001b[0m         sample_weight,\n\u001b[1;32m    544\u001b[0m         loss,\n\u001b[1;32m    545\u001b[0m         alpha,\n\u001b[1;32m    546\u001b[0m         beta,\n\u001b[1;32m    547\u001b[0m         max_iter,\n\u001b[1;32m    548\u001b[0m         tol,\n\u001b[1;32m    549\u001b[0m         verbose,\n\u001b[1;32m    550\u001b[0m         random_state,\n\u001b[1;32m    551\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m         max_squared_sum,\n\u001b[1;32m    553\u001b[0m         warm_start_sag,\n\u001b[1;32m    554\u001b[0m         is_saga\u001b[39m=\u001b[39m(solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    555\u001b[0m     )\n\u001b[1;32m    557\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[0;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[1;32m    326\u001b[0m     dataset,\n\u001b[1;32m    327\u001b[0m     coef_init,\n\u001b[1;32m    328\u001b[0m     intercept_init,\n\u001b[1;32m    329\u001b[0m     n_samples,\n\u001b[1;32m    330\u001b[0m     n_features,\n\u001b[1;32m    331\u001b[0m     n_classes,\n\u001b[1;32m    332\u001b[0m     tol,\n\u001b[1;32m    333\u001b[0m     max_iter,\n\u001b[1;32m    334\u001b[0m     loss,\n\u001b[1;32m    335\u001b[0m     step_size,\n\u001b[1;32m    336\u001b[0m     alpha_scaled,\n\u001b[1;32m    337\u001b[0m     beta_scaled,\n\u001b[1;32m    338\u001b[0m     sum_gradient_init,\n\u001b[1;32m    339\u001b[0m     gradient_memory_init,\n\u001b[1;32m    340\u001b[0m     seen_init,\n\u001b[1;32m    341\u001b[0m     num_seen_init,\n\u001b[1;32m    342\u001b[0m     fit_intercept,\n\u001b[1;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[1;32m    344\u001b[0m     intercept_decay,\n\u001b[1;32m    345\u001b[0m     is_saga,\n\u001b[1;32m    346\u001b[0m     verbose,\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[1;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    353\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define TF-IDF vectorization parameters\n",
    "ngram_range = (1, 2)  # Bigram setting\n",
    "max_features = 1000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "# Handle imbalance using ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log model and metrics in MLFlow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model name and experiment type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_ADASYN_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log model algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log detailed classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "# Optuna objective function for Logistic Regression\n",
    "def objective_logistic_regression(trial):\n",
    "    # Suggest hyperparameters\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\", None])\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-4, 10.0)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0) if penalty == \"elasticnet\" else None\n",
    "\n",
    "    # Set solver based on penalty\n",
    "    solver = \"saga\" if penalty in [\"l1\", \"elasticnet\"] else \"lbfgs\"\n",
    "\n",
    "    # Initialize LogisticRegression model\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        l1_ratio=l1_ratio,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna to optimize Logistic Regression hyperparameters\n",
    "def run_optuna_experiment():\n",
    "    # Create an Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_logistic_regression, n_trials=30)\n",
    "\n",
    "    # Get the best hyperparameters and retrain the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        penalty=best_params['penalty'],\n",
    "        C=best_params['C'],\n",
    "        solver=\"saga\" if best_params['penalty'] in [\"l1\", \"elasticnet\"] else \"lbfgs\",\n",
    "        l1_ratio=best_params.get('l1_ratio'),  # Only include if 'elasticnet'\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    # Log the best model with MLFlow\n",
    "    log_mlflow(\"LogisticRegression\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the Optuna experiment for Logistic Regression\n",
    "run_optuna_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
