{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sudhirjoon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sudhirjoon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/opt/anaconda3/lib/python3.11/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://capstone-yt-mlflow-bucket/542391321365143307', creation_time=1735485482149, experiment_id='542391321365143307', last_update_time=1735485482149, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://13.60.79.0:5000\")\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 14:31:46,917] A new study created in memory with name: no-name-97416aa0-73da-428c-9748-3002aeb3c265\n",
      "[I 2024-12-30 14:31:48,844] Trial 0 finished with value: 0.7263057411700532 and parameters: {'n_estimators': 106, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.7263057411700532.\n",
      "[I 2024-12-30 14:31:51,961] Trial 1 finished with value: 0.7179871812355108 and parameters: {'n_estimators': 203, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.7263057411700532.\n",
      "[I 2024-12-30 14:32:07,888] Trial 2 finished with value: 0.7178508114005182 and parameters: {'n_estimators': 276, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7263057411700532.\n",
      "[I 2024-12-30 14:32:10,978] Trial 3 finished with value: 0.7425337515341607 and parameters: {'n_estimators': 82, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 3 with value: 0.7425337515341607.\n",
      "[I 2024-12-30 14:35:50,407] Trial 4 finished with value: 0.6913950634119733 and parameters: {'n_estimators': 257, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: 0.7425337515341607.\n",
      "[I 2024-12-30 14:35:55,288] Trial 5 finished with value: 0.7460793672439656 and parameters: {'n_estimators': 116, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:41:59,056] Trial 6 finished with value: 0.6927587617618983 and parameters: {'n_estimators': 297, 'max_depth': 47, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:42:49,089] Trial 7 finished with value: 0.610800490931406 and parameters: {'n_estimators': 87, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:45:17,746] Trial 8 finished with value: 0.6642574662484658 and parameters: {'n_estimators': 170, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:48:08,826] Trial 9 finished with value: 0.6517114414291558 and parameters: {'n_estimators': 212, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:48:10,856] Trial 10 finished with value: 0.6688940406382108 and parameters: {'n_estimators': 131, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:48:13,629] Trial 11 finished with value: 0.7257602618300831 and parameters: {'n_estimators': 50, 'max_depth': 43, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:48:14,998] Trial 12 finished with value: 0.7267148506750307 and parameters: {'n_estimators': 55, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 5 with value: 0.7460793672439656.\n",
      "[I 2024-12-30 14:48:21,597] Trial 13 finished with value: 0.7464884767489431 and parameters: {'n_estimators': 142, 'max_depth': 41, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:24,505] Trial 14 finished with value: 0.7389881358243556 and parameters: {'n_estimators': 147, 'max_depth': 39, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:26,636] Trial 15 finished with value: 0.7126687576708032 and parameters: {'n_estimators': 135, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:34,237] Trial 16 finished with value: 0.7151234147006682 and parameters: {'n_estimators': 183, 'max_depth': 36, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:37,029] Trial 17 finished with value: 0.7421246420291832 and parameters: {'n_estimators': 113, 'max_depth': 43, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:41,379] Trial 18 finished with value: 0.7462157370789582 and parameters: {'n_estimators': 162, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:46,208] Trial 19 finished with value: 0.7377608073094232 and parameters: {'n_estimators': 231, 'max_depth': 33, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:48,184] Trial 20 finished with value: 0.6612573298786308 and parameters: {'n_estimators': 165, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.7464884767489431.\n",
      "[I 2024-12-30 14:48:54,497] Trial 21 finished with value: 0.7473066957588981 and parameters: {'n_estimators': 153, 'max_depth': 44, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 21 with value: 0.7473066957588981.\n",
      "[I 2024-12-30 14:48:58,533] Trial 22 finished with value: 0.7481249147688531 and parameters: {'n_estimators': 154, 'max_depth': 43, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 22 with value: 0.7481249147688531.\n",
      "[I 2024-12-30 14:49:05,505] Trial 23 finished with value: 0.7490795036138006 and parameters: {'n_estimators': 203, 'max_depth': 38, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:09,839] Trial 24 finished with value: 0.7358516296195282 and parameters: {'n_estimators': 194, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:15,740] Trial 25 finished with value: 0.7452611482340107 and parameters: {'n_estimators': 234, 'max_depth': 45, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:20,934] Trial 26 finished with value: 0.7376244374744306 and parameters: {'n_estimators': 222, 'max_depth': 38, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:24,492] Trial 27 finished with value: 0.7226237556252557 and parameters: {'n_estimators': 186, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:37,429] Trial 28 finished with value: 0.7137597163507432 and parameters: {'n_estimators': 248, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "[I 2024-12-30 14:49:39,389] Trial 29 finished with value: 0.7211236874403382 and parameters: {'n_estimators': 96, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.7490795036138006.\n",
      "\u001b[31m2024/12/30 14:49:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_ADASYN_TFIDF_Bigrams at: http://13.60.79.0:5000/#/experiments/542391321365143307/runs/e4ea801ee1434355b164a8272ef6de56\n",
      "🧪 View experiment at: http://13.60.79.0:5000/#/experiments/542391321365143307\n"
     ]
    }
   ],
   "source": [
    "# Define TF-IDF vectorization parameters\n",
    "ngram_range = (1, 2)  # Bigram setting\n",
    "max_features = 1000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "# Handle imbalance using ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log model and metrics in MLFlow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model name and experiment type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_ADASYN_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log model algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log detailed classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "# Optuna objective function for Random Forest\n",
    "def objective_rf(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    # Create the model with suggested parameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "# Run Optuna to optimize Random Forest hyperparameters\n",
    "def run_optuna_rf_experiment():\n",
    "    # Create an Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "    # Get the best hyperparameters and retrain the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        max_features=best_params['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Log the best model with MLFlow\n",
    "    log_mlflow(\"RandomForest\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the Optuna experiment for Random Forest\n",
    "run_optuna_rf_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
