{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://13.60.79.0:5000\")\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define TF-IDF vectorization parameters\n",
    "ngram_range = (1, 2)  # Bigram setting\n",
    "max_features = 1000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "# Handle imbalance using ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log model and metrics in MLFlow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model name and experiment type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_ADASYN_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log model algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log detailed classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "# Optuna objective function for KNN\n",
    "def objective_knn(trial):\n",
    "    # Suggest hyperparameters for KNN\n",
    "    n_neighbors = trial.suggest_int(\"n_neighbors\", 1, 20)  # Number of neighbors\n",
    "    weights = trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])  # Weight function\n",
    "    algorithm = trial.suggest_categorical(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"])  # Algorithm used for nearest neighbors search\n",
    "    leaf_size = trial.suggest_int(\"leaf_size\", 10, 50)  # Leaf size for tree-based algorithms\n",
    "\n",
    "    # Initialize the KNN model\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        algorithm=algorithm,\n",
    "        leaf_size=leaf_size\n",
    "    )\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Function to log model and metrics in MLFlow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model name and experiment type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_ADASYN_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log model algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log detailed classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "# Run Optuna to optimize KNN hyperparameters\n",
    "def run_optuna_experiment():\n",
    "    # Create an Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_knn, n_trials=30)\n",
    "\n",
    "    # Get the best hyperparameters and retrain the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = KNeighborsClassifier(\n",
    "        n_neighbors=best_params['n_neighbors'],\n",
    "        weights=best_params['weights'],\n",
    "        algorithm=best_params['algorithm'],\n",
    "        leaf_size=best_params['leaf_size']\n",
    "    )\n",
    "\n",
    "    # Log the best model with MLFlow\n",
    "    log_mlflow(\"KNN\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the Optuna experiment for KNN\n",
    "run_optuna_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
